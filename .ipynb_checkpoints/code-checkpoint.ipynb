{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from matplotlib.pyplot import imshow as ims\n",
    "import matplotlib\n",
    "import pytesseract \n",
    "import pylab as pl\n",
    "import math\n",
    "\n",
    "import box_to_order\n",
    "import improve_img\n",
    "import get_text\n",
    "\n",
    "#instalar imutils\n",
    "from imutils.object_detection import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siguientes pasos:\n",
    "# Lo primero es arreglar lo del orden, pedir a Noelia ayuda.\n",
    "# Definir que voy a hacer con las frases que consiga - Audio, texto y traducción y a pdf(quiza)\n",
    "# Hacer la interfaz visual donde meter las fotos y que haga lo que le comentes.\n",
    "# A partir de ahi ya mejorar el reconocimiento de texto a muerte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_imagen(imagen,alto, ancho):#cogemos imagen\n",
    "    image = cv2.imread(imagen)\n",
    "    #hacemos copia\n",
    "    orig = image.copy()\n",
    "    \n",
    "    #orig = tratar_imagen(orig)\n",
    "    #orig = tratar_img_2(orig)\n",
    "\n",
    "    #orig = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "    #sacamos alto y ancho\n",
    "    (H, W) = image.shape[:2]\n",
    "    \"\"\"\n",
    "    if H > 1000 and W >1500:\n",
    "        alto, ancho = 20\n",
    "    if H > 1000 and W >1500:\n",
    "        \n",
    "    if H > 1000 and W >1500:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    proporcion = H/W\n",
    "    \n",
    "    alto= int(alto * proporcion)\n",
    "        \n",
    "    #ponemos el nuevo alto y ancho, ¿PORQUE? Para hacerlo multiplo de 32, que se ajuste por tipo de pixel\n",
    "    (newW, newH) = (ancho*32, alto*32)\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "    \n",
    "\n",
    "    #lo aplicamos a la imagen y sacamos H y W de nuevo\n",
    "    image = cv2.resize(image, (newW ,newH))\n",
    "    \n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    return orig, image, rW, rH, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para detectar las palabra y etiquetar los puntos\n",
    "def detectar_palabras(image, H, W):\n",
    "    #nombre de las etiquetas principales, REVISAR\n",
    "    layerNames = [\"feature_fusion/Conv_7/Sigmoid\",\"feature_fusion/concat_3\"]\n",
    "    #Importamos el detector de texto, REVISAR que es el EAST\n",
    "    print(\"[INFO] loading EAST text detector...\")\n",
    "    #type=str\n",
    "    \n",
    "   \n",
    "    \n",
    "    net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "    #net = cv2.dnn.readNetFromDarknet(frozen_east_text_detection.pb)\n",
    "    #Construimos el cuadrito que va a rodear la imagen\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    start = time.time()\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    end = time.time()\n",
    "\n",
    "    #Muestra info sobre cuanto ha tardado en detectarlo\n",
    "    print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "    #Construimos los planos para meter los cuadritos alrrededor de los textos\n",
    "    #numRows te da el numero de palabras identificadas por sus\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    \n",
    "    \n",
    "    return numRows, numCols, scores, geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_esquinas(numRows, numCols, scores, geometry):\n",
    "    rects = []\n",
    "    confidences = []\n",
    "    for y in range(0, numRows):\n",
    "        #Con los scores, probabilidad de que este bien, seguido de los\n",
    "        #punto geometricos los ponemos en el texto para saber donde estan \n",
    "\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # loop sobre el numero de columnas\n",
    "        for x in range(0, numCols):\n",
    "            #metemos una variable de que si no hay suficiente confianza no lo meta, INVESTIGAR Y DECIDIR\n",
    "            if scoresData[x] < 0.05: #args[\"min_confidence\"]:\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature maps will\n",
    "            # be 4x smaller than the input image\n",
    "            # La imagen sera 4 veces mas pequeña?\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            #Extraer el angulo del texto para poder poner el recuadro girado\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            \"\"\"# compute both the starting and ending (x, y)-coordinates for\n",
    "            # the text prediction bounding box\"\"\"\n",
    "\n",
    "            #Crear los puntos exactos donde se debe poner el recuadro\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "\n",
    "            #Añadirlo a la lista de cuadros y de confianza\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "            \n",
    "            \n",
    "            \n",
    "    return rects, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recortar_palabras(orig, rects, confidences, rW, rH, padding , H, W):\n",
    "\n",
    "    #confThreshold = 0.4\n",
    "    #nmsThreshold = 0.5\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    #indices = cv2.dnn.NMSBoxesRotated(rects, confidences, confThreshold, nmsThreshold)\n",
    "    palabras_separadas = []\n",
    "    \n",
    "    boxes = box_to_order.get_orden(boxes)\n",
    "\n",
    "    \"\"\" \n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "\n",
    "        # in order to obtain a better OCR of the text we can potentially\n",
    "        # apply a bit of padding surrounding the bounding box -- here we\n",
    "        # are computing the deltas in both the x and y directions\n",
    "        dX = int((endX - startX) * padding)\n",
    "        dY = int((endY - startY) * padding)\n",
    "\n",
    "        startX = max(0, startX - dX)\n",
    "        startY = max(0, startY - dY)\n",
    "        endX = min(W, endX + (dX * 2))\n",
    "        endY = min(H, endY + (dY * 2))\n",
    "\n",
    "    \"\"\"\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "            #Hacemos un reescalado del cuadrito identificador acorde al que hicimos al principio.\n",
    "            startX = int(startX * rW)\n",
    "            if int(startX - (startX * padding))  > 0:\n",
    "                startX = int(startX - (startX * padding))\n",
    "            startY = int(startY * rH)\n",
    "            if int(startY - (startY * padding)) > 0:\n",
    "                startY = int(startY - (startY * padding))\n",
    "            endX = int(endX * rW)\n",
    "            if int(endX + (endX * padding)) > 0:\n",
    "                endX = int(endX + (endX * padding))\n",
    "            endY = int(endY * rH)\n",
    "            if int(endY + (endY * padding)) > 0:\n",
    "                endY = int(endY + (endY * padding))\n",
    "\n",
    "            #dX = int((endX - startX) * padding)\n",
    "            #dY = int((endY - startY) * padding)\n",
    "\n",
    "            #startX = max(0, startX - dX)\n",
    "            #startY = max(0, startY - dY)\n",
    "            #endX = min(W, endX + (dX * 2))\n",
    "            #endY = min(H, endY + (dY * 2))\n",
    "      \n",
    "            #Dibujar el rectangulo alrededor del texto en la imagen.\n",
    "            crop = orig[startY:endY,startX:endX]\n",
    "            cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 3)\n",
    "            palabras_separadas.append(crop)\n",
    "\n",
    "            # extract the actual padded ROI\n",
    "            roi = orig[startY:endY, startX:endX]\n",
    "\n",
    "    #print('Sx:',startX)\n",
    "    #print('Sy:',startY)\n",
    "    #print('Ex:',endX)\n",
    "    #print('Ey:',endY)\n",
    "    #print('Has conseguido {} palabras'.format(len(palabras_separadas)))\n",
    "    \n",
    "    return palabras_separadas, orig, boxes\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para el OCR\n",
    "def ocr(imagen):\n",
    "    config = (\"-l eng+deu+fra+spa --oem 1 --psm 10\")\n",
    "    text = pytesseract.image_to_string(imagen, config=config)\n",
    "    if text:\n",
    "        print(text)\n",
    "        return text\n",
    "    else:\n",
    "        print(\"No ha detectado nada\")\n",
    "    \n",
    "    \n",
    "#-l eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(nombre_imagen, size, resize = True, tratar = True, tratar_mas=True):\n",
    "    orig, image, rW, rH, H, W = preparar_imagen(nombre_imagen,size,size) #Multiplicar 32 por algo para hacer su multiplo\n",
    "    numRows, numCols, scores, geometry = detectar_palabras(image, H, W)\n",
    "    rects, confidences = get_esquinas(numRows, numCols, scores, geometry)\n",
    "    palabras, orig, boxes = recortar_palabras(orig, rects, confidences,rW, rH, 0.01 , H, W)\n",
    "    imagenes_finales = []\n",
    "    #return palabras\n",
    "    palabras_text = []\n",
    "    for i in range(len(palabras)):\n",
    "            if resize:\n",
    "                imagen_resize = improve_img.resize_imagen(palabras[i],int(2000/size))\n",
    "            if tratar:\n",
    "                imagen_tratada = improve_img.tratar_imagen(imagen_resize)\n",
    "            if tratar_mas:\n",
    "                imagen_final = improve_img.tratar_img_2(imagen_tratada)\n",
    "            else:\n",
    "                imagen_final = palabras[i]\n",
    "    \n",
    "            \n",
    "            imagenes_finales.append(imagen_final) \n",
    "            ocrtext = get_text.ocr(imagenes_finales[i])\n",
    "            palabras_text.append(ocrtext)\n",
    "            \n",
    "    frase = get_text.unificar_texto(palabras_text)\n",
    "    \n",
    "    return frase \n",
    "    return orig, imagenes_finales, palabras_text, frase \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n",
      "[INFO] text detection took 0.250259 seconds\n",
      "La mesa de ping pong solo podra usarse durante al horario de comida Comprendide entre las 13:00 las 15:00 IRON \n"
     ]
    }
   ],
   "source": [
    "frase = image_to_text(\"imagenes/ping.jpeg\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptacion entre el tamaño de la imagen, el size que se pasa, el valor para resicear y el porcentaje de pading.\n",
    "\n",
    "#Si la imagen es mas pequeña el size tiene que ser mas pequeño y el resice mas grande, y el pading mas grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idiomas = [afr (Afrikaans), amh (Amharic), ara (Arabic), asm (Assamese), aze (Azerbaijani), aze_cyrl (Azerbaijani - Cyrilic), bel (Belarusian), ben (Bengali), bod (Tibetan), bos (Bosnian), bre (Breton), bul (Bulgarian), cat (Catalan; Valencian), ceb (Cebuano), ces (Czech), chi_sim (Chinese simplified), chi_tra (Chinese traditional), chr (Cherokee), cym (Welsh), dan (Danish), deu (German), dzo (Dzongkha), ell (Greek, Modern, 1453-), eng (English), enm (English, Middle, 1100-1500), epo (Esperanto), equ (Math / equation detection module), est (Estonian), eus (Basque), fas (Persian), fin (Finnish), fra (French), frk (Frankish), frm (French, Middle, ca.1400-1600), gle (Irish), glg (Galician), grc (Greek, Ancient, to 1453), guj (Gujarati), hat (Haitian; Haitian Creole), heb (Hebrew), hin (Hindi), hrv (Croatian), hun (Hungarian), iku (Inuktitut), ind (Indonesian), isl (Icelandic), ita (Italian), ita_old (Italian - Old), jav (Javanese), jpn (Japanese), kan (Kannada), kat (Georgian), kat_old (Georgian - Old), kaz (Kazakh), khm (Central Khmer), kir (Kirghiz; Kyrgyz), kmr (Kurdish Kurmanji), kor (Korean), kor_vert (Korean vertical), kur (Kurdish), lao (Lao), lat (Latin), lav (Latvian), lit (Lithuanian), ltz (Luxembourgish), mal (Malayalam), mar (Marathi), mkd (Macedonian), mlt (Maltese), mon (Mongolian), mri (Maori), msa (Malay), mya (Burmese), nep (Nepali), nld (Dutch; Flemish), nor (Norwegian), oci (Occitan post 1500), ori (Oriya), osd (Orientation and script detection module), pan (Panjabi; Punjabi), pol (Polish), por (Portuguese), pus (Pushto; Pashto), que (Quechua), ron (Romanian; Moldavian; Moldovan), rus (Russian), san (Sanskrit), sin (Sinhala; Sinhalese), slk (Slovak), slv (Slovenian), snd (Sindhi), spa (Spanish; Castilian), spa_old (Spanish; Castilian - Old), sqi (Albanian), srp (Serbian), srp_latn (Serbian - Latin), sun (Sundanese), swa (Swahili), swe (Swedish), syr (Syriac), tam (Tamil), tat (Tatar), tel (Telugu), tgk (Tajik), tgl (Tagalog), tha (Thai), tir (Tigrinya), ton (Tonga), tur (Turkish), uig (Uighur; Uyghur), ukr (Ukrainian), urd (Urdu), uzb (Uzbek), uzb_cyrl (Uzbek - Cyrilic), vie (Vietnamese), yid (Yiddish), yor (Yoruba)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = image_to_text(\"imagenes/ping.jpeg\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig, imagenes_finales, palabras_text, frase = image_to_text(\"imagenes/ping.jpeg\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f7eea9c9dd71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'orig' is not defined"
     ]
    }
   ],
   "source": [
    "ims(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aplicacion():\n",
    "    def __init__(self):\n",
    "      \n",
    "        self.raiz = Tk()\n",
    "        self.raiz.geometry('450x700')\n",
    "        #self.raiz.resizable(width=False,height=False)\n",
    "        self.raiz.title('WordToAll')\n",
    "    \n",
    "        \n",
    "        self.titulo = Label (self.raiz, text=\"Word To All!\",font=(\"Arial Bold\", 30))\n",
    "        self.titulo.grid(column=0, row=0)\n",
    "        \n",
    "        self.subtitulo = Label (self.raiz, text=\"Introduce la imagen a la que quieres traducir el texto\",font=(\"Arial Bold\", 10))\n",
    "        self.subtitulo.grid(column=0, row=1)\n",
    "\n",
    "        #self.l1.pack(side=TOP)\n",
    "        \n",
    "        #self.txt.grid(column=1, row=0)\n",
    " \n",
    "        \n",
    "        self.tinfo = Text(self.raiz, width=30, height=15)\n",
    "        self.tinfo.grid(column=0, row=2)\n",
    "\n",
    "        \n",
    "        #Meter foto\n",
    "        self.binfo = ttk.Button(self.raiz, text='Importar Imagen', \n",
    "                                command=self.meter_foto)\n",
    "        self.binfo.grid(column=0, row=3)\n",
    "\n",
    "        #IDioma texto\n",
    "        self.idi_text = Label (self.raiz, text=\"¿En que idioma esta el texto de la foto?\",font=(\"Arial Bold\", 10))\n",
    "        self.idi_text.grid(column=0, row=6)\n",
    "        \n",
    "        #Caja idiomas\n",
    "        self.boxidioma = ttk.Combobox(self.raiz)\n",
    "        self.boxidioma['values']= (\"eng\", \"esp\", \"fra\" , 4, 5, \"Text\")\n",
    "        self.boxidioma.grid(column=0, row=7)\n",
    "                            \n",
    "        #Traducir\n",
    "        self.tradu = Label (self.raiz, text=\"¿A que idioma quieres traducirlo?\",font=(\"Arial Bold\", 10))\n",
    "        self.tradu.grid(column=0, row=8)\n",
    "        \n",
    "        #Caja tracuccion\n",
    "        self.boxtraductor = ttk.Combobox(self.raiz)\n",
    "        self.boxtraductor['values']= (\"eng\", \"esp\", \"fra\" , 4, 5, \"Text\")\n",
    "        self.boxtraductor.grid(column=0, row=9)\n",
    "        \n",
    "        #Meter foto\n",
    "        self.binfo = ttk.Button(self.raiz, text='Traducir', \n",
    "                                command=self.traducir)\n",
    "        self.binfo.grid(column=0, row=10)\n",
    "        \n",
    "        #Traducir\n",
    "        \n",
    "        #Salir\n",
    "        self.bsalir = ttk.Button(self.raiz, text='Salir', \n",
    "                                 command=self.raiz.destroy)\n",
    "        self.bsalir.grid(column=0, row=200)\n",
    "        \n",
    "        \n",
    "        # El foco de la aplicación se sitúa en el botón\n",
    "        # 'self.binfo' resaltando su borde. Si se presiona\n",
    "        # la barra espaciadora el botón que tiene el foco\n",
    "        # será pulsado. El foco puede cambiar de un widget\n",
    "        # a otro con la tecla tabulador [tab]\n",
    "        \n",
    "        self.binfo.focus_set()\n",
    "        self.raiz.mainloop()\n",
    "        \n",
    "    def meter_foto(self):\n",
    "        global pic\n",
    "        pic = filedialog.askopenfilename()\n",
    "        return pic\n",
    "    \n",
    "    def traducir(self):\n",
    "        frase1 = image_to_text(pic,20)\n",
    "        print(frase1)\n",
    "        return frase1\n",
    "    \n",
    "def main():\n",
    "    mi_app = Aplicacion()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pieces détachées et SA Spare parts and aftersales service /'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Libreria leer foto, pruebas.\n",
    "#imagen = cv2.imread(\"tesseract-python/piz1.jpeg\")\n",
    "#ocrtext1 = get_text.ocr(imagen)\n",
    "frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translator = Translator()\n",
    "#translated = translator.translate('안녕하세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduce(texto, leng='en'):              \n",
    "    traductor=Translator()\n",
    "    traduccion=traductor.translate('hola muy buenas')\n",
    "    return traduccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traduce(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from translate import translator\n",
    "#translator('en', 'zh-TW', 'Hello World!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import goslate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=100)\n",
    "gs = goslate.Goslate(executor=executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.translate(\"Hello word\", \"es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idiomas para traducir.\n",
    "#{u'gu': u'Gujarati', u'zh-TW': u'Chinese (Traditional)', u'ga': u'Irish', u'gl': u'Galician', u'la': u'Latin', u'lo': u'Lao', u'tr': u'Turkish', u'lv': u'Latvian', u'lt': u'Lithuanian', u'th': u'Thai', u'tg': u'Tajik', u'te': u'Telugu', u'ta': u'Tamil', u'yi': u'Yiddish', u'ceb': u'Cebuano', u'yo': u'Yoruba', u'de': u'German', u'da': u'Danish', u'el': u'Greek', u'eo': u'Esperanto', u'en': u'English', u'zh': u'Chinese', u'eu': u'Basque', u'et': u'Estonian', u'es': u'Spanish', u'ru': u'Russian', u'zh-CN': u'Chinese (Simplified)', u'ro': u'Romanian', u'be': u'Belarusian', u'bg': u'Bulgarian', u'ms': u'Malay', u'bn': u'Bengali', u'jw': u'Javanese', u'bs': u'Bosnian', u'ja': u'Japanese', u'ca': u'Catalan', u'cy': u'Welsh', u'cs': u'Czech', u'pt': u'Portuguese', u'tl': u'Filipino', u'pa': u'Punjabi', u'vi': u'Vietnamese', u'pl': u'Polish', u'hy': u'Armenian', u'hr': u'Croatian', u'ht': u'Haitian Creole', u'hu': u'Hungarian', u'hmn': u'Hmong', u'hi': u'Hindi', u'ha': u'Hausa', u'mg': u'Malagasy', u'uz': u'Uzbek', u'ml': u'Malayalam', u'mn': u'Mongolian', u'mi': u'Maori', u'mk': u'Macedonian', u'ur': u'Urdu', u'mt': u'Maltese', u'uk': u'Ukrainian', u'mr': u'Marathi', u'my': u'Myanmar (Burmese)', u'af': u'Afrikaans', u'sw': u'Swahili', u'is': u'Icelandic', u'it': u'Italian', u'iw': u'Hebrew', u'kn': u'Kannada', u'ar': u'Arabic', u'km': u'Khmer', u'zu': u'Zulu', u'az': u'Azerbaijani', u'id': u'Indonesian', u'ig': u'Igbo', u'nl': u'Dutch', u'no': u'Norwegian', u'ne': u'Nepali', u'ny': u'Chichewa', u'fr': u'French', u'fa': u'Persian', u'fi': u'Finnish', u'ka': u'Georgian', u'kk': u'Kazakh', u'sr': u'Serbian', u'sq': u'Albanian', u'ko': u'Korean', u'sv': u'Swedish', u'su': u'Sundanese', u'st': u'Sesotho', u'sk': u'Slovak', u'si': u'Sinhala', u'so': u'Somali', u'sl': u'Slovenian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unificar_texto(palabras_text):\n",
    "    palabra_unida = ' '.join(palabras_text)\n",
    "    print(palabra_unida)\n",
    "    return palabra_unida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 mesa de ping pong solo podra usarse durante el horario de comida Comprendido entre las 13:00 las 15:00 IRON! =ria'@\n"
     ]
    }
   ],
   "source": [
    "frase = unificar_texto(palabras_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS  \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "  \n",
    "\n",
    "def get_audio(palabra_unida):\n",
    "    mytext = palabra_unida\n",
    "    myobj = gTTS(mytext, lang='es-us')    \n",
    "    myobj.save(\"welcome.mp3\")\n",
    "    song = AudioSegment.from_mp3(\"welcome.mp3\")\n",
    "    play(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4ee0eb459a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'frase' is not defined"
     ]
    }
   ],
   "source": [
    "get_audio(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "##Porque no funciona si lo paso al visual\n",
    "\n",
    "def get_orden(lista_cord):\n",
    "    total_centro = []\n",
    "    definicion={}\n",
    "    count = 0\n",
    "    #Creando los puntos centrales.\n",
    "    lista_cord.tolist()\n",
    "    \n",
    "    for i in lista_cord:\n",
    "        count += 1\n",
    "        centro=[]\n",
    "        A = int((i[0] + i[2])/2)\n",
    "        centro.append(A)\n",
    "        B = int((i[1] + i[3])/2)\n",
    "        centro.append(B)\n",
    "        centro.append(count)\n",
    "        total_centro.append(centro)\n",
    "       \n",
    "    #Sacando los rangos. \n",
    "    total_rangos_y=[]\n",
    "    for i in lista_cord:\n",
    "        rango=[]\n",
    "        A = abs(int((i[1] - i[3])/2))\n",
    "    for c in total_centro:\n",
    "        rangos_y = []\n",
    "        B_1 = c[1] + A\n",
    "        rangos_y.append(B_1)\n",
    "        B_2 = c[1] - A\n",
    "        rangos_y.append(B_2)\n",
    "        rangos_y.append(c[0])\n",
    "        rangos_y.append(c[2])\n",
    "        total_rangos_y.append(rangos_y)\n",
    "    \n",
    "    \n",
    "    #Creando los grupos de los rangos\n",
    "    rangos_ordenados= sorted(total_rangos_y)\n",
    "    gas = []\n",
    "    for r_y in range(len(rangos_ordenados)):\n",
    "        que_rango=[]\n",
    "        que_rango.append(rangos_ordenados[r_y])\n",
    "        for r_y2 in range(len(rangos_ordenados)):\n",
    "            if rangos_ordenados[r_y][0] <= rangos_ordenados[r_y2][0]*1.1 and rangos_ordenados[r_y][1] >= rangos_ordenados[r_y2][1]*0.9:\n",
    "                que_rango.append(r_y2)\n",
    "        gas.append(que_rango)\n",
    "        \n",
    "    #Si solo con rangos no funciona.\n",
    "    #for grupos in range(len(gas)):\n",
    "        #for n_grupos in range(len(gas)):\n",
    "            #if gas[grupos][2] == gas[n_grupos][2] and gas[grupos][2] == gas[n_grupos][2]:\n",
    "                #print('Tikit')\n",
    "                \n",
    "    #Ordenando primero por la x y luego por la y, ya tenemos el orden correcto.\n",
    "    from operator import itemgetter\n",
    "    import operator \n",
    "    #gas = sorted(gas, key=operator.itemgetter(1, 2))\n",
    "    gas.sort(key=lambda x: x[0][2])\n",
    "    gas.sort(key=lambda x: x[1]) \n",
    "\n",
    "    \n",
    "    #Crear una lista con las posiciones que deberian ser\n",
    "    orden_final=[]\n",
    "    cuenta = 0\n",
    "    for orden in gas:\n",
    "        l_cuenta=[]\n",
    "        cuenta += 1\n",
    "        l_cuenta.append(cuenta)\n",
    "        l_cuenta.append(orden[0][3])\n",
    "        orden_final.append(l_cuenta)\n",
    "    \n",
    "    #Meter toda la info en un dicc\n",
    "    for num in range(len(total_centro)):\n",
    "        definicion[num]='Centros:',total_centro[num],'Rangos y:', gas[num], 'Orden:',orden_final[num]\n",
    "        orden_final[num]=orden_final[num]\n",
    "    \n",
    "    #Añadir a cada source su posicion concreta\n",
    "    lista_cord_copy = lista_cord.tolist()\n",
    " \n",
    "    for i in range(1,len(lista_cord)+1):\n",
    "        for j in orden_final:          \n",
    "                if i == j[1]:\n",
    "                    lista_cord_copy[i-1].append(j[0])\n",
    "                    #lista_cord_copy[3] = j[0]\n",
    "                    pass\n",
    "    \n",
    "    \n",
    "    #ordenando por posicion.\n",
    "    lista_cord_copy.sort(key=lambda x: x[4])\n",
    "    \n",
    "    for i in range(len(lista_cord_copy)):\n",
    "          lista_cord_copy[i].pop(4)\n",
    "    \n",
    "    \n",
    "    lista_cord_copy = abs(np.array(lista_cord_copy))\n",
    "    return lista_cord_copy\n",
    "            \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Orde' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c62127ca6bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Cemtro +- altura/2 = rango\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mOrde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Orde' is not defined"
     ]
    }
   ],
   "source": [
    "#Cemtro +- altura/2 = rango\n",
    "Orde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partes_imagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6765e139f5c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gas\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartes_imagen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partes_imagen' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"gas\",partes_imagen[5])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para pasar a blanco y negro\n",
    "#(thresh, blackAndWhiteImage) = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tratado2 = cv2.medianBlur(blackAndWhiteImage, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusiones a tener en cuenta\n",
    "\n",
    "# - Cuanto mas se afina el resize mejor funciona al reconocedor de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
