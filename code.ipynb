{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from matplotlib.pyplot import imshow as ims\n",
    "import matplotlib\n",
    "import pytesseract \n",
    "import pylab as pl\n",
    "import math\n",
    "\n",
    "import box_to_order\n",
    "import improve_img\n",
    "import get_text\n",
    "\n",
    "#instalar imutils\n",
    "from imutils.object_detection import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Siguientes pasos:\n",
    "# Lo primero es arreglar lo del orden, pedir a Noelia ayuda.\n",
    "# Definir que voy a hacer con las frases que consiga - Audio, texto y traducción y a pdf(quiza)\n",
    "# Hacer la interfaz visual donde meter las fotos y que haga lo que le comentes.\n",
    "# A partir de ahi ya mejorar el reconocimiento de texto a muerte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_imagen(imagen,alto, ancho):#cogemos imagen\n",
    "    image = cv2.imread(imagen)\n",
    "    #hacemos copia\n",
    "    orig = image.copy()\n",
    "    \n",
    "    #orig = tratar_imagen(orig)\n",
    "    #orig = tratar_img_2(orig)\n",
    "\n",
    "    #orig = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "    #sacamos alto y ancho\n",
    "    (H, W) = image.shape[:2]\n",
    "    #ponemos el nuevo alto y ancho, ¿PORQUE? Para hacerlo multiplo de 32, que se ajuste por tipo de pixel\n",
    "    (newW, newH) = (alto, ancho)\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "    #lo aplicamos a la imagen y sacamos H y W de nuevo\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    return orig, image, rW, rH, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para detectar las palabra y etiquetar los puntos\n",
    "def detectar_palabras(image, H, W):\n",
    "    #nombre de las etiquetas principales, REVISAR\n",
    "    layerNames = [\"feature_fusion/Conv_7/Sigmoid\",\"feature_fusion/concat_3\"]\n",
    "    #Importamos el detector de texto, REVISAR que es el EAST\n",
    "    print(\"[INFO] loading EAST text detector...\")\n",
    "    #type=str\n",
    "    \n",
    "   \n",
    "    \n",
    "    net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "    #net = cv2.dnn.readNetFromDarknet(frozen_east_text_detection.pb)\n",
    "    #Construimos el cuadrito que va a rodear la imagen\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    start = time.time()\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    end = time.time()\n",
    "\n",
    "    #Muestra info sobre cuanto ha tardado en detectarlo\n",
    "    print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "    #Construimos los planos para meter los cuadritos alrrededor de los textos\n",
    "    #numRows te da el numero de palabras identificadas por sus\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    \n",
    "    \n",
    "    return numRows, numCols, scores, geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_esquinas(numRows, numCols, scores, geometry):\n",
    "    rects = []\n",
    "    confidences = []\n",
    "    for y in range(0, numRows):\n",
    "        #Con los scores, probabilidad de que este bien, seguido de los\n",
    "        #punto geometricos los ponemos en el texto para saber donde estan \n",
    "\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # loop sobre el numero de columnas\n",
    "        for x in range(0, numCols):\n",
    "            #metemos una variable de que si no hay suficiente confianza no lo meta, INVESTIGAR Y DECIDIR\n",
    "            if scoresData[x] < 0.05: #args[\"min_confidence\"]:\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature maps will\n",
    "            # be 4x smaller than the input image\n",
    "            # La imagen sera 4 veces mas pequeña?\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            #Extraer el angulo del texto para poder poner el recuadro girado\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            \"\"\"# compute both the starting and ending (x, y)-coordinates for\n",
    "            # the text prediction bounding box\"\"\"\n",
    "\n",
    "            #Crear los puntos exactos donde se debe poner el recuadro\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "\n",
    "            #Añadirlo a la lista de cuadros y de confianza\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "            \n",
    "            \n",
    "            \n",
    "    return rects, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recortar_palabras(orig, rects, confidences, rW, rH, padding , H, W):\n",
    "\n",
    "    #confThreshold = 0.4\n",
    "    #nmsThreshold = 0.5\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    #indices = cv2.dnn.NMSBoxesRotated(rects, confidences, confThreshold, nmsThreshold)\n",
    "    palabras_separadas = []\n",
    "    \n",
    "    boxes = get_orden(boxes)\n",
    "\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        #Hacemos un reescalado del cuadrito identificador acorde al que hicimos al principio.\n",
    "        startX = int(startX * rW)\n",
    "        if int(startX - (startX * padding))  > 0:\n",
    "            startX = int(startX - (startX * padding))\n",
    "        startY = int(startY * rH)\n",
    "        if int(startY - (startY * padding)) > 0:\n",
    "            startY = int(startY - (startY * padding))\n",
    "        endX = int(endX * rW)\n",
    "        if int(endX + (endX * padding)) > 0:\n",
    "            endX = int(endX + (endX * padding))\n",
    "        endY = int(endY * rH)\n",
    "        if int(endY + (endY * padding)) > 0:\n",
    "            endY = int(endY + (endY * padding))\n",
    "        \n",
    "        #dX = int((endX - startX) * padding)\n",
    "        #dY = int((endY - startY) * padding)\n",
    "        \n",
    "        #startX = max(0, startX - dX)\n",
    "        #startY = max(0, startY - dY)\n",
    "        #endX = min(W, endX + (dX * 2))\n",
    "        #endY = min(H, endY + (dY * 2))\n",
    "        \n",
    "        #Dibujar el rectangulo alrededor del texto en la imagen.\n",
    "        crop = orig[startY:endY,startX:endX]\n",
    "        cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 3)\n",
    "        palabras_separadas.append(crop)\n",
    "        \n",
    "        # extract the actual padded ROI\n",
    "        roi = orig[startY:endY, startX:endX]\n",
    "\n",
    "    #print('Sx:',startX)\n",
    "    #print('Sy:',startY)\n",
    "    #print('Ex:',endX)\n",
    "    #print('Ey:',endY)\n",
    "    #print('Has conseguido {} palabras'.format(len(palabras_separadas)))\n",
    "    \n",
    "    return palabras_separadas, orig, boxes\n",
    "    # Mostrar la imagen ya con el texto detectado\n",
    "    #cv2.imshow(\"Text Detection\", orig)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para el OCR\n",
    "def ocr(imagen):\n",
    "    config = (\"-l eng --oem 1 --psm 7\")\n",
    "    text = pytesseract.image_to_string(imagen, config=config)\n",
    "    if text:\n",
    "        print(text)\n",
    "        return text\n",
    "    else:\n",
    "        print(\"No ha detectado nada\")\n",
    "    \n",
    "    \n",
    "#-l eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_1(nombre_imagen, size, resize = True, tratar = True, tratar_mas=True):\n",
    "    orig, image, rW, rH, H, W = preparar_imagen(nombre_imagen,32*size,32*size) #Multiplicar 32 por algo para hacer su multiplo\n",
    "    numRows, numCols, scores, geometry = detectar_palabras(image, H, W)\n",
    "    rects, confidences = get_esquinas(numRows, numCols, scores, geometry)\n",
    "    palabras, orig, boxes = recortar_palabras(orig, rects, confidences,rW, rH, 0.01 , H, W)\n",
    "    imagenes_finales = []\n",
    "    #return palabras\n",
    "    palabras_text = []\n",
    "    for i in range(len(palabras)):\n",
    "        if resize:\n",
    "            imagen_resize = improve_img.resize_imagen(palabras[i],100)\n",
    "        if tratar:\n",
    "            imagen_tratada = improve_img.tratar_imagen(imagen_resize)\n",
    "        if tratar_mas:\n",
    "            imagen_final = improve_img.tratar_img_2(imagen_tratada)\n",
    "        else:\n",
    "            imagen_final = palabras[i]\n",
    "    \n",
    "            \n",
    "        imagenes_finales.append(imagen_final) \n",
    "        ocrtext = get_text.ocr(imagenes_finales[i])\n",
    "        palabras_text.append(ocrtext)\n",
    "    return orig, imagenes_finales, palabras_text, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n",
      "[INFO] text detection took 0.561515 seconds\n",
      "(64, 100, 3)\n",
      "L2\n",
      "(27, 100, 3)\n",
      "mesa\n",
      "(69, 100, 3)\n",
      "de\n",
      "(49, 100, 3)\n",
      "ping\n",
      "(34, 100, 3)\n",
      "pong\n",
      "(39, 100, 3)\n",
      "solo\n",
      "(37, 100, 3)\n",
      "podra\n",
      "(20, 100, 3)\n",
      "usarse\n",
      "(20, 100, 3)\n",
      "durante\n",
      "(78, 100, 3)\n",
      "el\n",
      "(23, 100, 3)\n",
      "horario\n",
      "(64, 100, 3)\n",
      "de\n",
      "(23, 100, 3)\n",
      "comida\n",
      "(15, 100, 3)\n",
      "Comprendido\n",
      "(31, 100, 3)\n",
      "entre\n",
      "(53, 100, 3)\n",
      "las\n",
      "(32, 100, 3)\n",
      "13:00\n",
      "(55, 100, 3)\n",
      "las\n",
      "(34, 100, 3)\n",
      "15:00\n",
      "(40, 100, 3)\n",
      "IRON!\n",
      "(38, 100, 3)\n",
      "=ria'@\n"
     ]
    }
   ],
   "source": [
    "orig, imagenes_finales, palabras_text = prueba_1(\"tesseract-python/ping.jpeg\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libreria leer foto, pruebas.\n",
    "#imagen = cv2.imread(\"tesseract-python/piz1.jpeg\")\n",
    "#ocrtext1 = get_text.ocr(imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unificar_texto(palabras_text):\n",
    "    palabra_unida = ' '.join(palabras_text)\n",
    "    print(palabra_unida)\n",
    "    return palabra_unida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 mesa de ping pong solo podra usarse durante el horario de comida 13:00 Comprendido las entre 15:00 las IRON! =ria'@\n"
     ]
    }
   ],
   "source": [
    "frase = unificar_texto(palabras_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS  \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "  \n",
    "\n",
    "def get_audio(palabra_unida):\n",
    "    mytext = palabra_unida\n",
    "    myobj = gTTS(mytext, lang='es-us')    \n",
    "    myobj.save(\"welcome.mp3\")\n",
    "    song = AudioSegment.from_mp3(\"welcome.mp3\")\n",
    "    play(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_audio(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cord = [[ 22 ,218, 197, 280], #5\n",
    " [201 ,212 ,298, 281], #6\n",
    " [ 56  ,38 ,149 ,106], #1\n",
    " [156 ,130 ,214 ,191], #4\n",
    " [103 ,138 ,143 ,192], #3\n",
    " [157  ,39 ,274 ,110]] #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cord = np.array(lista_cord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Porque no funciona si lo paso al visual\n",
    "\n",
    "def get_orden(lista_cord):\n",
    "    total_centro = []\n",
    "    definicion={}\n",
    "    count = 0\n",
    "    #Creando los puntos centrales.\n",
    "    lista_cord.tolist()\n",
    "    \n",
    "    for i in lista_cord:\n",
    "        count += 1\n",
    "        centro=[]\n",
    "        A = int((i[0] + i[2])/2)\n",
    "        centro.append(A)\n",
    "        B = int((i[1] + i[3])/2)\n",
    "        centro.append(B)\n",
    "        centro.append(count)\n",
    "        total_centro.append(centro)\n",
    "       \n",
    "    #Sacando los rangos. \n",
    "    total_rangos_y=[]\n",
    "    for i in lista_cord:\n",
    "        rango=[]\n",
    "        A = abs(int((i[1] - i[3])/2))\n",
    "    for c in total_centro:\n",
    "        rangos_y = []\n",
    "        B_1 = c[1] + A\n",
    "        rangos_y.append(B_1)\n",
    "        B_2 = c[1] - A\n",
    "        rangos_y.append(B_2)\n",
    "        rangos_y.append(c[0])\n",
    "        rangos_y.append(c[2])\n",
    "        total_rangos_y.append(rangos_y)\n",
    "    \n",
    "    \n",
    "    #Creando los grupos de los rangos\n",
    "    rangos_ordenados= sorted(total_rangos_y)\n",
    "    gas = []\n",
    "    for r_y in range(len(rangos_ordenados)):\n",
    "        que_rango=[]\n",
    "        que_rango.append(rangos_ordenados[r_y])\n",
    "        for r_y2 in range(len(rangos_ordenados)):\n",
    "            if rangos_ordenados[r_y][0] <= rangos_ordenados[r_y2][0]*1.1 and rangos_ordenados[r_y][1] >= rangos_ordenados[r_y2][1]*0.9:\n",
    "                que_rango.append(r_y2)\n",
    "        gas.append(que_rango)\n",
    "        \n",
    "    #Si solo con rangos no funciona.\n",
    "    #for grupos in range(len(gas)):\n",
    "        #for n_grupos in range(len(gas)):\n",
    "            #if gas[grupos][2] == gas[n_grupos][2] and gas[grupos][2] == gas[n_grupos][2]:\n",
    "                #print('Tikit')\n",
    "                \n",
    "    #Ordenando primero por la x y luego por la y, ya tenemos el orden correcto.\n",
    "    from operator import itemgetter\n",
    "    import operator \n",
    "    #gas = sorted(gas, key=operator.itemgetter(1, 2))\n",
    "    gas.sort(key=lambda x: x[0][2])\n",
    "    gas.sort(key=lambda x: x[1]) \n",
    "\n",
    "    \n",
    "    #Crear una lista con las posiciones que deberian ser\n",
    "    orden_final=[]\n",
    "    cuenta = 0\n",
    "    for orden in gas:\n",
    "        l_cuenta=[]\n",
    "        cuenta += 1\n",
    "        l_cuenta.append(cuenta)\n",
    "        l_cuenta.append(orden[0][3])\n",
    "        orden_final.append(l_cuenta)\n",
    "    \n",
    "    #Meter toda la info en un dicc\n",
    "    for num in range(len(total_centro)):\n",
    "        definicion[num]='Centros:',total_centro[num],'Rangos y:', gas[num], 'Orden:',orden_final[num]\n",
    "        orden_final[num]=orden_final[num]\n",
    "    \n",
    "    #Añadir a cada source su posicion concreta\n",
    "    lista_cord_copy = lista_cord.tolist()\n",
    " \n",
    "    for i in range(1,len(lista_cord)+1):\n",
    "        for j in orden_final:          \n",
    "                if i == j[1]:\n",
    "                    lista_cord_copy[i-1].append(j[0])\n",
    "                    #lista_cord_copy[3] = j[0]\n",
    "                    pass\n",
    "    \n",
    "    \n",
    "    #ordenando por posicion.\n",
    "    lista_cord_copy.sort(key=lambda x: x[4])\n",
    "    \n",
    "    for i in range(len(lista_cord_copy)):\n",
    "          lista_cord_copy[i].pop(4)\n",
    "    \n",
    "    \n",
    "    lista_cord_copy = abs(np.array(lista_cord_copy))\n",
    "    return lista_cord_copy\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54, 112,  93, 145],\n",
       "       [108, 115, 202, 148],\n",
       "       [216, 109, 257, 149],\n",
       "       [269, 111, 339, 158],\n",
       "       [352, 118, 439, 159],\n",
       "       [450, 113, 521, 153],\n",
       "       [ 86, 165, 181, 211],\n",
       "       [189, 176, 309, 206],\n",
       "       [318, 172, 453, 207],\n",
       "       [466, 171, 495, 207],\n",
       "       [131, 223, 256, 259],\n",
       "       [270, 226, 310, 260],\n",
       "       [315, 226, 445, 263],\n",
       "       [ 83, 293, 324, 338],\n",
       "       [335, 298, 422, 331],\n",
       "       [433, 298, 482, 333],\n",
       "       [151, 346, 246, 381],\n",
       "       [284, 350, 331, 382],\n",
       "       [353, 349, 434, 382],\n",
       "       [255, 470, 333, 506],\n",
       "       [256, 506, 336, 539]])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gasgas = np.array(gasgas)\n",
    "total_centro = get_orden(gasgas)\n",
    "total_centro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54, 112,  93, 145],\n",
       "       [108, 115, 202, 148],\n",
       "       [216, 109, 257, 149],\n",
       "       [269, 111, 339, 158],\n",
       "       [352, 118, 439, 159],\n",
       "       [450, 113, 521, 153],\n",
       "       [ 86, 165, 181, 211],\n",
       "       [189, 176, 309, 206],\n",
       "       [318, 172, 453, 207],\n",
       "       [466, 171, 495, 207],\n",
       "       [131, 223, 256, 259],\n",
       "       [270, 226, 310, 260],\n",
       "       [315, 226, 445, 263],\n",
       "       [ 83, 293, 324, 338],\n",
       "       [335, 298, 422, 331],\n",
       "       [433, 298, 482, 333],\n",
       "       [151, 346, 246, 381],\n",
       "       [284, 350, 331, 382],\n",
       "       [353, 349, 434, 382],\n",
       "       [255, 470, 333, 506],\n",
       "       [256, 506, 336, 539]])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_centro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-978e4d4d8b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moperator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitemgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_centro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "total_centro.sort(key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cemtro +- altura/2 = rango\n",
    "Orde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [120, 238],\n",
       " 1: [206, 289],\n",
       " 2: [47, 127],\n",
       " 3: [143, 202],\n",
       " 4: [120, 167],\n",
       " 5: [98, 192]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_centro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f43e1054128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.scatter(total_centro[0][0],total_centro[0][1])\n",
    "\n",
    "#Con el centro calculado lo siguiente seria buscar un patron que sea capaz de poner en su lugar cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partes_imagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6765e139f5c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gas\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartes_imagen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partes_imagen' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"gas\",partes_imagen[5])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para pasar a blanco y negro\n",
    "#(thresh, blackAndWhiteImage) = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tratado2 = cv2.medianBlur(blackAndWhiteImage, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusiones a tener en cuenta\n",
    "\n",
    "# - Cuanto mas se afina el resize mejor funciona al reconocedor de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
